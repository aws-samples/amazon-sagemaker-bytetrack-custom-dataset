{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11ff828c",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6e1d8",
   "metadata": {},
   "source": [
    "## 1. Prepare raw data\n",
    "\n",
    "Download raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae33cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir datasets\n",
    "!wget https://raw.githubusercontent.com/ifzhang/FairMOT/master/videos/MOT16-03.mp4 -O datasets/MOT16-03.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b627ed1",
   "metadata": {},
   "source": [
    "Split video into clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def split_video(video_path, clip_dir=\"./datasets/clips\"):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not os.path.exists(clip_dir):\n",
    "        os.makedirs(clip_dir)\n",
    "    \n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "    \n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "    frame_num = 200\n",
    "    \n",
    "    frame_cnt = 0\n",
    "    clip_cnt = 0\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            if frame_cnt % frame_num == 0:\n",
    "                if frame_cnt > 0:\n",
    "                    out.release()\n",
    "                \n",
    "                clip_path = f\"{clip_dir}/sample_{clip_cnt}.mp4\"\n",
    "                out = cv2.VideoWriter(clip_path, fourcc, fps, (frame_width, frame_height))\n",
    "                print(f\"save clip: {clip_path}\")\n",
    "                clip_cnt += 1\n",
    "            out.write(frame)\n",
    "            frame_cnt += 1\n",
    "        else:\n",
    "            break\n",
    "    out.release()\n",
    "\n",
    "clip_dir = \"./datasets/clips\"\n",
    "split_video('./datasets/MOT16-03.mp4', clip_dir=clip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c09a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"sagemaker-us-east-1-822507008821\"\n",
    "prefix = \"sm-bytetrack\"\n",
    "sample_data_s3uri = f\"s3://{bucket_name}/{prefix}/sample-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd35512",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $clip_dir $sample_data_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef844646",
   "metadata": {},
   "source": [
    "## 2. Label raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4df4dd0",
   "metadata": {},
   "source": [
    "- Step-1: create a Private teams\n",
    "- Step-2: Add a worker into the private team you created\n",
    "- Step-3: Create a labeling job\n",
    "- Step-4: Label data\n",
    "\n",
    "Once finishing a labeling task, you can get the following annotation directory in the defined S3 path.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img width=300 src=\"img/gt_structure.png\">\n",
    "    <figcaption>Ground Truth Structure</figcaption>\n",
    "</div>\n",
    "\n",
    "Under manifest directory, there should be an `out` folder created if we finish labeling all files.\n",
    "<div align=\"center\">\n",
    "    <img width=300 src=\"img/gt_manifest_structure.png\">\n",
    "    <figcaption>Manifest in Ground Truth Structure</figcaption>\n",
    "</div>\n",
    "\n",
    "You will see a file `output.manifest` like this:\n",
    "<div align=\"center\">\n",
    "    <img width=600 src=\"img/out_manifest.png\">\n",
    "    <figcaption>output.manifest</figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b60b0",
   "metadata": {},
   "source": [
    "Refer to [Use Amazon SageMaker Ground Truth to Label Data](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html) for guide of labeling data. You can choose either video files or frame files to label data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f03eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
