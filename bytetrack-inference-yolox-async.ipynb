{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ByteTrack Inference with Amazon SageMaker\n",
    "\n",
    "This notebook will demonstrate how to create an endpoint for real time inference with the trained FairMOT model.\n",
    "\n",
    "## 1. SageMaker Initialization \n",
    "First we upgrade SageMaker to the latest version. If your notebook is already using latest Sagemaker 2.x API, you may skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade pip\n",
    "! python3 -m pip install --upgrade sagemaker\n",
    "! pip install cython_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "from time import strftime,gmtime\n",
    "\n",
    "role = (\n",
    "    get_execution_role()\n",
    ")  # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f\"SageMaker Execution Role:{role}\")\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "print(f'AWS account:{account}')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "sm_session = sagemaker.session.Session()\n",
    "aws_region = session.region_name\n",
    "print(f\"AWS region:{aws_region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy an Asynchronous Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to complete training job on [bytetrack-training.ipynb](bytetrack-training.ipynb) before running the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r s3_model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare model.tag.gz\n",
    "\n",
    "To use scripts related to ByteTrack on the endpoint, we need to put tracking script and model into the same folder and compress the folder as the model.tar.gz, and then upload it to S3 bucket for creating a model. The following is the structure of model.tar.gz:\n",
    "<img src=\"img/async_inference_model.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp $s3_model_uri ./sagemaker-serving-async/model.tar.gz\n",
    "!cd sagemaker-serving-async && tar -xvf model.tar.gz && rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile download_tracking_async_inference.sh\n",
    "git clone --filter=blob:none --no-checkout --depth 1 --sparse https://github.com/ifzhang/ByteTrack.git && \\\n",
    "cd ByteTrack && \\\n",
    "git sparse-checkout set yolox && \\\n",
    "git checkout && \\\n",
    "cd ..\n",
    "cp -r ByteTrack/yolox sagemaker-serving-async/code/\n",
    "cp container-batch-inference/byte_tracker.py sagemaker-serving-async/code/yolox/tracker/\n",
    "sudo rm -r ByteTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bash download_tracking_async_inference.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd sagemaker-serving-async && tar -cvzf model.tar.gz * && aws s3 cp model.tar.gz $s3_model_uri && rm model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to handle the large video file, we need to explicitly set the payload size and response timeout with environment variables in `PyTorchModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pytorch_model = PyTorchModel(\n",
    "    model_data=s3_model_uri,\n",
    "    role=role,\n",
    "    entry_point=\"inference.py\",\n",
    "    framework_version=\"1.7.1\",\n",
    "    sagemaker_session=sm_session,\n",
    "    py_version=\"py3\",\n",
    "    env={\n",
    "        'TS_MAX_REQUEST_SIZE': '1000000000', #default max request size is 6 Mb for torchserve, need to update it to support the 1GB input payload\n",
    "        'TS_MAX_RESPONSE_SIZE': '1000000000',\n",
    "        'TS_DEFAULT_RESPONSE_TIMEOUT': '900', # max timeout is 15mins (900 seconds)\n",
    "        'INPUT_WIDTH': '1440',\n",
    "        'INPUT_HEIGHT': '800'\n",
    "    }\n",
    ")\n",
    "\n",
    "pytorch_model.create(\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_endpoint_config_name = f\"YoloxAsyncEndpointConfig-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "\n",
    "bucket_name = <bucket_name> # S3 Bucket name\n",
    "prefix = <prefix> # Prefix\n",
    "\n",
    "s3_output_path = f\"s3://{bucket_name}/{prefix}/output/async\"\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "boto_session = sagemaker_session.boto_session\n",
    "sagemaker_client = boto_session.client('sagemaker')\n",
    "\n",
    "create_endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=async_endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": pytorch_model.name,\n",
    "            \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "            \"InitialInstanceCount\": 1\n",
    "        }\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": s3_output_path,\n",
    "            #  Optionally specify Amazon SNS topics\n",
    "            #\"NotificationConfig\": {\n",
    "            #  \"SuccessTopic\": success_topic,\n",
    "            #  \"ErrorTopic\": error_topic,\n",
    "            #}\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 2\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(f\"Created EndpointConfig: {create_endpoint_config_response['EndpointConfigArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_endpoint_name = f\"bytetrack-{strftime('%Y-%m-%d-%H-%M-%S', gmtime())}\"\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "    EndpointName=async_endpoint_name,\n",
    "    EndpointConfigName=async_endpoint_config_name\n",
    ")\n",
    "print(f\"Creating Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "print(\"Waiting for endpoint to create...\")\n",
    "waiter.wait(EndpointName=async_endpoint_name)\n",
    "resp = sagemaker_client.describe_endpoint(EndpointName=async_endpoint_name)\n",
    "print(f\"Endpoint Status: {resp['EndpointStatus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Asynchronous Inference Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"datasets/MOT16-03.mp4\"\n",
    "input_s3_path = f\"s3://{bucket_name}/{prefix}/inputs/MOT16-03.mp4\"\n",
    "!mkdir datasets\n",
    "!wget https://raw.githubusercontent.com/ifzhang/FairMOT/master/videos/MOT16-03.mp4 -O $data_path\n",
    "!aws s3 cp $data_path $input_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "\n",
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=async_endpoint_name, \n",
    "    InputLocation=input_s3_path\n",
    ")\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "import urllib\n",
    "import sys\n",
    "\n",
    "def get_output(output_location):\n",
    "    output_url = urllib.parse.urlparse(output_location)\n",
    "    bucket = output_url.netloc\n",
    "    key = output_url.path[1:]\n",
    "    while True:\n",
    "        try:\n",
    "            return sm_session.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'NoSuchKey':\n",
    "                print(\"waiting for output...\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = get_output(output_location)\n",
    "print(f\"Output size in bytes: {((sys.getsizeof(output)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_res = \"./datasets/tracking_res.txt\"\n",
    "!aws s3 cp $output_location $tracking_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the tracking result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os.path as osp\n",
    "import os\n",
    "import io\n",
    "from yolox.utils.visualize import plot_tracking\n",
    "\n",
    "with open(tracking_res, 'r') as f:\n",
    "    tracking_res = json.load(f)\n",
    "\n",
    "frame_dict = {}\n",
    "for track in tracking_res:\n",
    "    track = track.split(',')\n",
    "    track = list(map(float, track))\n",
    "    frame_id = track[0]\n",
    "    bboxes = track[1:]\n",
    "    \n",
    "    if frame_id not in frame_dict:\n",
    "        frame_dict[frame_id] = [bboxes]\n",
    "    else:\n",
    "        frame_dict[frame_id].append(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from yolox.tracking_utils.timer import Timer\n",
    "\n",
    "cap = cv2.VideoCapture(data_path)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "save_path = \"datasets/tracking_res.mp4\"\n",
    "\n",
    "vid_writer = cv2.VideoWriter(\n",
    "    save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height))\n",
    ")\n",
    "\n",
    "frame_id = 0\n",
    "\n",
    "while True:\n",
    "    ret_val, frame = cap.read()\n",
    "    if ret_val:\n",
    "        if frame_id in frame_dict:\n",
    "            bboxes = frame_dict[frame_id]\n",
    "            online_tlwhs = []\n",
    "            online_ids = []\n",
    "            online_scores = []\n",
    "\n",
    "            for bbox in bboxes:\n",
    "                online_tlwhs.append(bbox[1:5])\n",
    "                online_ids.append(bbox[0])\n",
    "                online_scores.append(bbox[5])\n",
    "\n",
    "            online_im = plot_tracking(\n",
    "                frame, online_tlwhs, online_ids, frame_id=frame_id + 1, fps=25\n",
    "            )\n",
    "        else:\n",
    "            online_im = frame\n",
    "            \n",
    "        vid_writer.write(online_im)\n",
    "    else:\n",
    "        break\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "vid_writer.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download `datasets/tracking_res.mp4` and check the visualized result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
